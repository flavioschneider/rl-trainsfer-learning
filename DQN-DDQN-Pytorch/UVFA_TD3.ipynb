{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ico/Desktop/RL/RLenv/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import gym\n",
    "# import roboschool\n",
    "import sys\n",
    "\n",
    "#%%\n",
    "\n",
    "import metaworld\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.l1 = nn.Linear(in_dim, hid_dim)\n",
    "        self.l2 = nn.Linear(hid_dim, hid_dim)\n",
    "        self.l3 = nn.Linear(hid_dim, out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         print(x)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    \"\"\"Buffer to store tuples of experience replay\"\"\"\n",
    "\n",
    "    def __init__(self, max_size=1000000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_size (int): total amount of tuples to store\n",
    "        \"\"\"\n",
    "\n",
    "        self.storage = []\n",
    "        self.max_size = max_size\n",
    "        self.ptr = 0\n",
    "\n",
    "    def add(self, data):\n",
    "        \"\"\"Add experience tuples to buffer\n",
    "\n",
    "        Args:\n",
    "            data (tuple): experience replay tuple\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.storage) == self.max_size:\n",
    "            self.storage[int(self.ptr)] = data\n",
    "            self.ptr = (self.ptr + 1) % self.max_size\n",
    "        else:\n",
    "            self.storage.append(data)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Samples a random amount of experiences from buffer of batch size\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): size of sample\n",
    "        \"\"\"\n",
    "\n",
    "        ind = np.random.randint(0, len(self.storage), size=batch_size)\n",
    "        states, actions, next_states, rewards, dones = [], [], [], [], []\n",
    "\n",
    "        for i in ind:\n",
    "            s, a, s_, r, d = self.storage[i]\n",
    "            states.append(np.array(s, copy=False))\n",
    "            actions.append(np.array(a, copy=False))\n",
    "            next_states.append(np.array(s_, copy=False))\n",
    "            rewards.append(np.array(r, copy=False))\n",
    "            dones.append(np.array(d, copy=False))\n",
    "\n",
    "        return np.array(states), np.array(actions), np.array(next_states), np.array(rewards).reshape(-1, 1), np.array(\n",
    "            dones).reshape(-1, 1)\n",
    "\n",
    "    def save(self):\n",
    "        np_buffer = np.asarray(self.storage)\n",
    "        with open('replaybuffer' + str(env._last_rand_vec[0]) + '_' + str(env._last_rand_vec[1]) + '.npy', 'wb') as f:\n",
    "            print(\"Saving replay buffer in \", f)\n",
    "            np.save(f, np_buffer)\n",
    "            \n",
    "    def load(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.storage = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    \"\"\"Initialize parameters and build model.\n",
    "        Args:\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            max_action (float): highest action to take\n",
    "            seed (int): Random seed\n",
    "            h1_units (int): Number of nodes in first hidden layer\n",
    "            h2_units (int): Number of nodes in second hidden layer\n",
    "\n",
    "        Return:\n",
    "            action output of network with tanh activation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state_dim, action_dim, max_action):\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.l1 = nn.Linear(state_dim, 100)\n",
    "        self.l2 = nn.Linear(100, 100)\n",
    "        self.l3 = nn.Linear(100, action_dim)\n",
    "\n",
    "        self.max_action = max_action\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = self.max_action * torch.tanh(self.l3(x))\n",
    "        return x\n",
    "    \n",
    "    def load(self, filename=\"best_avg\"):\n",
    "        state_dict = torch.load(filename)\n",
    "        for el in state_dict.keys():\n",
    "            e = state_dict[el]\n",
    "            print(e.shape)\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 39])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([4, 100])\n",
      "torch.Size([4])\n",
      "torch.Size([100, 39])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([4, 100])\n",
      "torch.Size([4])\n",
      "torch.Size([100, 39])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([4, 100])\n",
      "torch.Size([4])\n",
      "torch.Size([100, 39])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([4, 100])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "state_dim = 39\n",
    "target_actor1,target_actor2,target_actor3,target_actor4 = Actor(state_dim, 4, 1.0),Actor(state_dim, 4, 1.0),Actor(state_dim, 4, 1.0),Actor(state_dim, 4, 1.0)\n",
    "target_actor1.load('models/best_avg-0.09_0.86_actor.pth')\n",
    "target_actor2.load('models/best_avg-0.09_0.89_actor.pth')\n",
    "target_actor3.load('models/best_avg0.07_0.86_actor.pth')\n",
    "target_actor4.load('models/best_avg0.07_0.89_actor.pth')\n",
    "target_actors = [target_actor1,target_actor2,target_actor3,target_actor4 ]\n",
    "for a in target_actors:\n",
    "    a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1, r2, r3, r4 = ReplayBuffer(), ReplayBuffer(), ReplayBuffer(), ReplayBuffer()\n",
    "\n",
    "r1.load('replaybuffers/replaybuffer-0.09_0.86.npy')\n",
    "r2.load('replaybuffers/replaybuffer-0.09_0.89.npy')\n",
    "r3.load('replaybuffers/replaybuffer0.07_0.86.npy')\n",
    "r4.load('replaybuffers/replaybuffer0.07_0.89.npy')\n",
    "\n",
    "replay_buffers = [r1,r2,r3,r4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_MLP = MLP(2, 100, 4)\n",
    "state_MLP = MLP(39, 100, 4)\n",
    "goal_optimizer = torch.optim.Adam(goal_MLP.parameters(), lr=1e-3)\n",
    "state_optimizer = torch.optim.Adam(state_MLP.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mfgossi\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/frl/RL-transfer-learning/runs/3jzm6bcz\" target=\"_blank\">fragrant-wildflower-38</a></strong> to <a href=\"https://wandb.ai/frl/RL-transfer-learning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"RL-transfer-learning\", entity=\"frl\", settings=wandb.Settings(start_method=\"fork\"))\n",
    "wandb.watch(goal_MLP, log_freq=10000)\n",
    "wandb.watch(state_MLP, log_freq=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 91.23941802978516\n",
      "loss: 77.10416412353516\n",
      "loss: 86.05088806152344\n",
      "loss: 81.11884307861328\n",
      "loss: 88.03341674804688\n",
      "loss: 69.64188385009766\n",
      "loss: 80.38008117675781\n",
      "loss: 79.09566497802734\n",
      "loss: 84.76258850097656\n",
      "loss: 64.92466735839844\n",
      "loss: 70.6837158203125\n",
      "loss: 70.5404052734375\n",
      "loss: 81.7104263305664\n",
      "loss: 51.95756149291992\n",
      "loss: 64.40206146240234\n",
      "loss: 62.23408126831055\n",
      "loss: 73.98877716064453\n",
      "loss: 41.77582931518555\n",
      "loss: 52.174903869628906\n",
      "loss: 66.32875061035156\n",
      "loss: 86.42039489746094\n",
      "loss: 39.15113067626953\n",
      "loss: 57.56932067871094\n",
      "loss: 66.44692993164062\n",
      "loss: 81.00995635986328\n",
      "loss: 34.931949615478516\n",
      "loss: 55.200660705566406\n",
      "loss: 72.35468292236328\n",
      "loss: 80.92044830322266\n",
      "loss: 34.985679626464844\n",
      "loss: 54.57392501831055\n",
      "loss: 60.51991271972656\n",
      "loss: 74.8302230834961\n",
      "loss: 40.13710021972656\n",
      "loss: 51.880104064941406\n",
      "loss: 65.5450439453125\n",
      "loss: 72.92865753173828\n",
      "loss: 36.32811737060547\n",
      "loss: 51.54486083984375\n",
      "loss: 57.11216354370117\n",
      "loss: 79.06961822509766\n",
      "loss: 32.7033576965332\n",
      "loss: 50.003997802734375\n",
      "loss: 61.86842346191406\n",
      "loss: 75.57500457763672\n",
      "loss: 29.122037887573242\n",
      "loss: 55.55385971069336\n",
      "loss: 68.1793441772461\n",
      "loss: 78.91609954833984\n",
      "loss: 36.35875701904297\n",
      "loss: 55.76435470581055\n",
      "loss: 66.60936737060547\n",
      "loss: 79.72452545166016\n",
      "loss: 35.22682571411133\n",
      "loss: 56.853267669677734\n",
      "loss: 71.36006927490234\n",
      "loss: 86.26558685302734\n",
      "loss: 36.560062408447266\n",
      "loss: 58.00922393798828\n",
      "loss: 62.85509490966797\n",
      "loss: 78.091796875\n",
      "loss: 39.9600944519043\n",
      "loss: 56.87775802612305\n",
      "loss: 66.52658081054688\n",
      "loss: 82.24266815185547\n",
      "loss: 35.86033248901367\n",
      "loss: 55.49909591674805\n",
      "loss: 58.76478958129883\n",
      "loss: 73.7030258178711\n",
      "loss: 35.68397521972656\n",
      "loss: 57.06948471069336\n",
      "loss: 59.81035614013672\n",
      "loss: 79.59940338134766\n",
      "loss: 37.55125427246094\n",
      "loss: 49.530540466308594\n",
      "loss: 67.89552307128906\n",
      "loss: 78.31039428710938\n",
      "loss: 37.64178466796875\n",
      "loss: 54.38935852050781\n",
      "loss: 63.91184997558594\n",
      "loss: 75.48773193359375\n",
      "loss: 39.29891586303711\n",
      "loss: 56.32955551147461\n",
      "loss: 68.32360076904297\n",
      "loss: 79.6965103149414\n",
      "loss: 32.99729537963867\n",
      "loss: 54.579864501953125\n",
      "loss: 71.64436340332031\n",
      "loss: 73.66106414794922\n",
      "loss: 36.598087310791016\n",
      "loss: 53.76737594604492\n",
      "loss: 61.143333435058594\n",
      "loss: 77.20989227294922\n",
      "loss: 37.92940902709961\n",
      "loss: 55.14175033569336\n",
      "loss: 65.00894165039062\n",
      "loss: 67.1689453125\n",
      "loss: 37.19266128540039\n",
      "loss: 52.08222579956055\n",
      "loss: 71.61228942871094\n",
      "loss: 73.48839569091797\n",
      "loss: 38.44239807128906\n",
      "loss: 46.4603157043457\n",
      "loss: 60.24237060546875\n",
      "loss: 76.6321029663086\n",
      "loss: 32.611228942871094\n",
      "loss: 52.86186981201172\n",
      "loss: 65.37133026123047\n",
      "loss: 77.20447540283203\n",
      "loss: 36.37834930419922\n",
      "loss: 51.59312438964844\n",
      "loss: 61.81739807128906\n",
      "loss: 73.71733856201172\n",
      "loss: 36.70077896118164\n",
      "loss: 56.36349868774414\n",
      "loss: 52.46400833129883\n",
      "loss: 73.1956787109375\n",
      "loss: 37.530277252197266\n",
      "loss: 51.248775482177734\n",
      "loss: 60.5557861328125\n",
      "loss: 73.73104095458984\n",
      "loss: 34.86922836303711\n",
      "loss: 53.901023864746094\n",
      "loss: 65.31417083740234\n",
      "loss: 73.10932922363281\n",
      "loss: 32.39952087402344\n",
      "loss: 51.75302505493164\n",
      "loss: 59.715579986572266\n",
      "loss: 71.98031616210938\n",
      "loss: 35.7841796875\n",
      "loss: 50.519466400146484\n",
      "loss: 61.38695526123047\n",
      "loss: 70.61349487304688\n",
      "loss: 32.112796783447266\n",
      "loss: 53.8062629699707\n",
      "loss: 64.23966979980469\n",
      "loss: 61.49442672729492\n",
      "loss: 35.77996063232422\n",
      "loss: 49.60982894897461\n",
      "loss: 64.55126953125\n",
      "loss: 76.04662322998047\n",
      "loss: 34.9996337890625\n",
      "loss: 52.20491027832031\n",
      "loss: 66.12676239013672\n",
      "loss: 64.7537612915039\n",
      "loss: 32.08907699584961\n",
      "loss: 49.86594009399414\n",
      "loss: 65.59593200683594\n",
      "loss: 69.03630828857422\n",
      "loss: 36.580970764160156\n",
      "loss: 55.47861862182617\n",
      "loss: 65.83350372314453\n",
      "loss: 68.39553833007812\n",
      "loss: 36.349220275878906\n",
      "loss: 54.70663070678711\n",
      "loss: 61.62810134887695\n",
      "loss: 59.600826263427734\n",
      "loss: 39.241676330566406\n",
      "loss: 51.55159378051758\n",
      "loss: 60.27402877807617\n",
      "loss: 65.20331573486328\n",
      "loss: 34.21772003173828\n",
      "loss: 53.1287841796875\n",
      "loss: 66.06892395019531\n",
      "loss: 66.2813949584961\n",
      "loss: 33.922576904296875\n",
      "loss: 56.31303405761719\n",
      "loss: 64.27928924560547\n",
      "loss: 64.28086853027344\n",
      "loss: 32.84611892700195\n",
      "loss: 51.04486083984375\n",
      "loss: 63.08949279785156\n",
      "loss: 61.993446350097656\n",
      "loss: 33.644805908203125\n",
      "loss: 54.82684326171875\n",
      "loss: 71.94775390625\n",
      "loss: 57.22639846801758\n",
      "loss: 37.97806167602539\n",
      "loss: 48.18790054321289\n",
      "loss: 60.05108642578125\n",
      "loss: 54.99958419799805\n",
      "loss: 35.02439498901367\n",
      "loss: 50.362003326416016\n",
      "loss: 60.91454315185547\n",
      "loss: 49.308311462402344\n",
      "loss: 33.91547393798828\n",
      "loss: 48.15483856201172\n",
      "loss: 57.75933837890625\n",
      "loss: 60.15093994140625\n",
      "loss: 33.5789909362793\n",
      "loss: 49.7625732421875\n",
      "loss: 62.237667083740234\n",
      "loss: 61.146812438964844\n",
      "loss: 32.86490249633789\n",
      "loss: 49.6869010925293\n",
      "loss: 64.0379638671875\n",
      "loss: 57.572818756103516\n",
      "loss: 31.196258544921875\n",
      "loss: 48.24661636352539\n",
      "loss: 62.098716735839844\n",
      "loss: 45.15414810180664\n",
      "loss: 33.6565055847168\n",
      "loss: 47.78650665283203\n",
      "loss: 56.04792022705078\n",
      "loss: 55.97015380859375\n",
      "loss: 32.978736877441406\n",
      "loss: 44.11053466796875\n",
      "loss: 59.54316711425781\n",
      "loss: 62.191654205322266\n",
      "loss: 29.90696144104004\n",
      "loss: 53.2652702331543\n",
      "loss: 67.58858489990234\n",
      "loss: 51.935791015625\n",
      "loss: 32.335514068603516\n",
      "loss: 47.90711212158203\n",
      "loss: 54.3845100402832\n",
      "loss: 65.82054901123047\n",
      "loss: 37.97480392456055\n",
      "loss: 47.876380920410156\n",
      "loss: 63.425926208496094\n",
      "loss: 51.93619918823242\n",
      "loss: 32.68012237548828\n",
      "loss: 47.628028869628906\n",
      "loss: 59.16659164428711\n",
      "loss: 55.38411331176758\n",
      "loss: 29.94692611694336\n",
      "loss: 45.294349670410156\n",
      "loss: 58.391937255859375\n",
      "loss: 45.084617614746094\n",
      "loss: 29.271760940551758\n",
      "loss: 46.77045440673828\n",
      "loss: 66.03927612304688\n",
      "loss: 46.50774002075195\n",
      "loss: 33.5239372253418\n",
      "loss: 50.59722900390625\n",
      "loss: 62.35578155517578\n",
      "loss: 49.243141174316406\n",
      "loss: 28.895936965942383\n",
      "loss: 53.04659652709961\n",
      "loss: 54.65351104736328\n",
      "loss: 51.77396774291992\n",
      "loss: 27.82769203186035\n",
      "loss: 47.85338592529297\n",
      "loss: 62.17708206176758\n",
      "loss: 46.5710334777832\n",
      "loss: 30.085187911987305\n",
      "loss: 49.49790573120117\n",
      "loss: 64.44412994384766\n",
      "loss: 55.29121398925781\n",
      "loss: 32.225345611572266\n",
      "loss: 47.90258026123047\n",
      "loss: 66.36998748779297\n",
      "loss: 56.113525390625\n",
      "loss: 32.81329345703125\n",
      "loss: 47.99312210083008\n",
      "loss: 64.29082489013672\n",
      "loss: 49.544551849365234\n",
      "loss: 31.8936824798584\n",
      "loss: 49.92939758300781\n",
      "loss: 57.84526824951172\n",
      "loss: 53.96742630004883\n",
      "loss: 34.756961822509766\n",
      "loss: 47.25293731689453\n",
      "loss: 68.05674743652344\n",
      "loss: 42.577606201171875\n",
      "loss: 32.93055725097656\n",
      "loss: 47.02434539794922\n",
      "loss: 68.3277359008789\n",
      "loss: 47.63874435424805\n",
      "loss: 31.499357223510742\n",
      "loss: 48.523216247558594\n",
      "loss: 53.028202056884766\n",
      "loss: 54.35212707519531\n",
      "loss: 33.84730911254883\n",
      "loss: 49.670143127441406\n",
      "loss: 59.77761459350586\n",
      "loss: 53.10365676879883\n",
      "loss: 33.98638916015625\n",
      "loss: 50.23025131225586\n",
      "loss: 51.88463592529297\n",
      "loss: 56.087303161621094\n",
      "loss: 29.45073127746582\n",
      "loss: 43.996421813964844\n",
      "loss: 56.940528869628906\n",
      "loss: 45.29816818237305\n",
      "loss: 28.78523826599121\n",
      "loss: 45.37169647216797\n",
      "loss: 62.64251708984375\n",
      "loss: 49.70813751220703\n",
      "loss: 28.475481033325195\n",
      "loss: 46.756099700927734\n",
      "loss: 57.32971954345703\n",
      "loss: 57.73289489746094\n",
      "loss: 30.088651657104492\n",
      "loss: 44.32131576538086\n",
      "loss: 52.46953582763672\n",
      "loss: 51.4090461730957\n",
      "loss: 31.94257926940918\n",
      "loss: 49.075923919677734\n",
      "loss: 56.45928955078125\n",
      "loss: 53.28000259399414\n",
      "loss: 27.897396087646484\n",
      "loss: 49.09592056274414\n",
      "loss: 65.35979461669922\n",
      "loss: 51.88707733154297\n",
      "loss: 29.440876007080078\n",
      "loss: 45.761390686035156\n",
      "loss: 61.218441009521484\n",
      "loss: 48.50565719604492\n",
      "loss: 25.755945205688477\n",
      "loss: 47.81370162963867\n",
      "loss: 58.563961029052734\n",
      "loss: 51.82488250732422\n",
      "loss: 32.42257308959961\n",
      "loss: 44.18004608154297\n",
      "loss: 52.25639343261719\n",
      "loss: 56.774593353271484\n",
      "loss: 26.031940460205078\n",
      "loss: 42.73590087890625\n",
      "loss: 61.053749084472656\n",
      "loss: 54.139312744140625\n",
      "loss: 28.333797454833984\n",
      "loss: 41.746891021728516\n",
      "loss: 54.16273498535156\n",
      "loss: 53.26905059814453\n",
      "loss: 28.961593627929688\n",
      "loss: 44.83976745605469\n",
      "loss: 56.883785247802734\n",
      "loss: 47.798030853271484\n",
      "loss: 27.276840209960938\n",
      "loss: 47.74052047729492\n",
      "loss: 55.20521926879883\n",
      "loss: 50.1469841003418\n",
      "loss: 30.223196029663086\n",
      "loss: 45.47199249267578\n",
      "loss: 63.594085693359375\n",
      "loss: 48.45103073120117\n",
      "loss: 25.953880310058594\n",
      "loss: 47.94037628173828\n",
      "loss: 53.83192825317383\n",
      "loss: 50.14362335205078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25.975696563720703\n",
      "loss: 44.558563232421875\n",
      "loss: 59.83476638793945\n",
      "loss: 51.28065872192383\n",
      "loss: 27.452959060668945\n",
      "loss: 46.50086975097656\n",
      "loss: 66.97631072998047\n",
      "loss: 54.78048324584961\n",
      "loss: 27.355195999145508\n",
      "loss: 47.852474212646484\n",
      "loss: 60.76836013793945\n",
      "loss: 47.53154373168945\n",
      "loss: 29.991390228271484\n",
      "loss: 45.766170501708984\n",
      "loss: 67.91533660888672\n",
      "loss: 40.74586486816406\n",
      "loss: 26.925477981567383\n",
      "loss: 49.71335983276367\n",
      "loss: 59.70710372924805\n",
      "loss: 49.15348434448242\n",
      "loss: 26.039594650268555\n",
      "loss: 50.29188537597656\n",
      "loss: 56.05305862426758\n",
      "loss: 53.989742279052734\n",
      "loss: 31.971651077270508\n",
      "loss: 46.550174713134766\n",
      "loss: 63.11445617675781\n",
      "loss: 53.197330474853516\n",
      "loss: 25.98990821838379\n",
      "loss: 44.39219284057617\n",
      "loss: 57.434593200683594\n",
      "loss: 46.016597747802734\n",
      "loss: 27.191776275634766\n",
      "loss: 45.054039001464844\n",
      "loss: 60.39162826538086\n",
      "loss: 55.426841735839844\n",
      "loss: 24.82500648498535\n",
      "loss: 42.421043395996094\n",
      "loss: 54.96552658081055\n",
      "loss: 48.24217224121094\n",
      "loss: 31.31805992126465\n",
      "loss: 48.484214782714844\n",
      "loss: 57.87973403930664\n",
      "loss: 45.95610427856445\n",
      "loss: 28.936674118041992\n",
      "loss: 43.81333541870117\n",
      "loss: 67.6795425415039\n",
      "loss: 45.22685241699219\n",
      "loss: 28.32795524597168\n",
      "loss: 43.73237609863281\n",
      "loss: 58.32642364501953\n",
      "loss: 44.012969970703125\n",
      "loss: 30.08297348022461\n",
      "loss: 46.271244049072266\n",
      "loss: 59.05901336669922\n",
      "loss: 48.73452377319336\n",
      "loss: 24.02290916442871\n",
      "loss: 43.71629333496094\n",
      "loss: 56.152347564697266\n",
      "loss: 45.47163391113281\n",
      "loss: 24.70623016357422\n",
      "loss: 41.026912689208984\n",
      "loss: 56.605472564697266\n",
      "loss: 47.471405029296875\n",
      "loss: 23.6696720123291\n",
      "loss: 45.104957580566406\n",
      "loss: 60.380401611328125\n",
      "loss: 48.50103759765625\n",
      "loss: 24.900537490844727\n",
      "loss: 46.40580368041992\n",
      "loss: 57.82101058959961\n",
      "loss: 48.17304992675781\n",
      "loss: 28.885000228881836\n",
      "loss: 42.88117218017578\n",
      "loss: 53.01421356201172\n",
      "loss: 44.19105529785156\n",
      "loss: 28.51282501220703\n",
      "loss: 41.84485626220703\n",
      "loss: 55.6049919128418\n",
      "loss: 46.367706298828125\n",
      "loss: 23.082368850708008\n",
      "loss: 50.381675720214844\n",
      "loss: 57.684207916259766\n",
      "loss: 45.662986755371094\n",
      "loss: 27.489362716674805\n",
      "loss: 41.02557373046875\n",
      "loss: 56.647891998291016\n",
      "loss: 43.132484436035156\n",
      "loss: 24.742475509643555\n",
      "loss: 47.38284683227539\n",
      "loss: 55.63177490234375\n",
      "loss: 48.792903900146484\n",
      "loss: 27.067068099975586\n",
      "loss: 42.35947799682617\n",
      "loss: 54.8040885925293\n",
      "loss: 48.82589340209961\n",
      "loss: 21.794904708862305\n",
      "loss: 39.14594650268555\n",
      "loss: 61.43675994873047\n",
      "loss: 45.15835189819336\n",
      "loss: 27.620773315429688\n",
      "loss: 44.52943801879883\n",
      "loss: 59.96088409423828\n",
      "loss: 42.9002571105957\n",
      "loss: 25.791664123535156\n",
      "loss: 43.561275482177734\n",
      "loss: 51.5003662109375\n",
      "loss: 47.283714294433594\n",
      "loss: 24.07695770263672\n",
      "loss: 43.56875991821289\n",
      "loss: 57.46709060668945\n",
      "loss: 41.202327728271484\n",
      "loss: 29.506193161010742\n",
      "loss: 39.8110466003418\n",
      "loss: 65.08637237548828\n",
      "loss: 49.5220832824707\n",
      "loss: 25.654399871826172\n",
      "loss: 44.612918853759766\n",
      "loss: 59.3997802734375\n",
      "loss: 45.13491439819336\n",
      "loss: 24.437225341796875\n",
      "loss: 37.26862335205078\n",
      "loss: 51.61497116088867\n",
      "loss: 48.204742431640625\n",
      "loss: 20.094776153564453\n",
      "loss: 43.109336853027344\n",
      "loss: 56.30353927612305\n",
      "loss: 39.525596618652344\n",
      "loss: 25.95578956604004\n",
      "loss: 47.353885650634766\n",
      "loss: 55.779605865478516\n",
      "loss: 50.28470230102539\n",
      "loss: 26.514236450195312\n",
      "loss: 40.62897872924805\n",
      "loss: 45.4614143371582\n",
      "loss: 49.860809326171875\n",
      "loss: 26.460472106933594\n",
      "loss: 40.271728515625\n",
      "loss: 49.89048767089844\n",
      "loss: 41.136016845703125\n",
      "loss: 22.23789405822754\n",
      "loss: 37.32843780517578\n",
      "loss: 52.6863899230957\n",
      "loss: 37.892578125\n",
      "loss: 19.431415557861328\n",
      "loss: 40.5879020690918\n",
      "loss: 43.91421890258789\n",
      "loss: 43.23906326293945\n",
      "loss: 31.712202072143555\n",
      "loss: 39.925601959228516\n",
      "loss: 47.483795166015625\n",
      "loss: 39.88460922241211\n",
      "loss: 21.190654754638672\n",
      "loss: 36.766571044921875\n",
      "loss: 65.49203491210938\n",
      "loss: 43.303409576416016\n",
      "loss: 19.34729766845703\n",
      "loss: 35.89265060424805\n",
      "loss: 63.19136428833008\n",
      "loss: 47.18686294555664\n",
      "loss: 22.466821670532227\n",
      "loss: 41.9273681640625\n",
      "loss: 54.97850799560547\n",
      "loss: 42.10348129272461\n",
      "loss: 24.246368408203125\n",
      "loss: 36.62535095214844\n",
      "loss: 51.55291748046875\n",
      "loss: 45.923423767089844\n",
      "loss: 26.20137596130371\n",
      "loss: 42.45037841796875\n",
      "loss: 47.111324310302734\n",
      "loss: 41.93067169189453\n",
      "loss: 24.11677360534668\n",
      "loss: 40.36079025268555\n",
      "loss: 62.102577209472656\n",
      "loss: 42.46754455566406\n",
      "loss: 23.633012771606445\n",
      "loss: 37.4306755065918\n",
      "loss: 55.80826950073242\n",
      "loss: 39.58679962158203\n",
      "loss: 21.74424171447754\n",
      "loss: 41.005035400390625\n",
      "loss: 48.09163284301758\n",
      "loss: 51.15956497192383\n",
      "loss: 24.204999923706055\n",
      "loss: 41.56727600097656\n",
      "loss: 56.09375\n",
      "loss: 38.62199020385742\n",
      "loss: 27.742671966552734\n",
      "loss: 42.39431381225586\n",
      "loss: 46.820472717285156\n",
      "loss: 43.868064880371094\n",
      "loss: 21.62588119506836\n",
      "loss: 44.17424392700195\n",
      "loss: 46.44755172729492\n",
      "loss: 45.634742736816406\n",
      "loss: 22.564193725585938\n",
      "loss: 42.268192291259766\n",
      "loss: 57.26040267944336\n",
      "loss: 46.074058532714844\n",
      "loss: 28.771047592163086\n",
      "loss: 39.7336540222168\n",
      "loss: 55.831058502197266\n",
      "loss: 46.86109924316406\n",
      "loss: 23.939193725585938\n",
      "loss: 39.464534759521484\n",
      "loss: 63.708290100097656\n",
      "loss: 44.06776809692383\n",
      "loss: 26.43576431274414\n",
      "loss: 39.4847297668457\n",
      "loss: 56.17625045776367\n",
      "loss: 41.83973693847656\n",
      "loss: 28.761734008789062\n",
      "loss: 39.98381423950195\n",
      "loss: 54.65766143798828\n",
      "loss: 42.71953201293945\n",
      "loss: 22.449209213256836\n",
      "loss: 38.024295806884766\n",
      "loss: 50.72974395751953\n",
      "loss: 42.02253723144531\n",
      "loss: 22.532508850097656\n",
      "loss: 38.813053131103516\n",
      "loss: 42.89202117919922\n",
      "loss: 41.6568603515625\n",
      "loss: 27.898399353027344\n",
      "loss: 34.72574996948242\n",
      "loss: 48.85770797729492\n",
      "loss: 49.83582305908203\n",
      "loss: 21.625579833984375\n",
      "loss: 46.14728927612305\n",
      "loss: 53.45665740966797\n",
      "loss: 45.92694854736328\n",
      "loss: 25.13248062133789\n",
      "loss: 40.056251525878906\n",
      "loss: 54.07599639892578\n",
      "loss: 41.45079803466797\n",
      "loss: 24.54620933532715\n",
      "loss: 39.76178741455078\n",
      "loss: 56.630062103271484\n",
      "loss: 37.99714279174805\n",
      "loss: 23.743072509765625\n",
      "loss: 37.91084289550781\n",
      "loss: 46.29815673828125\n",
      "loss: 43.273040771484375\n",
      "loss: 21.419565200805664\n",
      "loss: 39.62495040893555\n",
      "loss: 49.67746353149414\n",
      "loss: 39.12584686279297\n",
      "loss: 23.165145874023438\n",
      "loss: 38.9315071105957\n",
      "loss: 45.407474517822266\n",
      "loss: 35.52696990966797\n",
      "loss: 22.77088737487793\n",
      "loss: 33.37739562988281\n",
      "loss: 54.584625244140625\n",
      "loss: 39.3781623840332\n",
      "loss: 18.251110076904297\n",
      "loss: 39.34687805175781\n",
      "loss: 52.8393669128418\n",
      "loss: 43.52590560913086\n",
      "loss: 22.15106201171875\n",
      "loss: 37.2907829284668\n",
      "loss: 51.53941345214844\n",
      "loss: 45.30628204345703\n",
      "loss: 22.128177642822266\n",
      "loss: 36.105228424072266\n",
      "loss: 45.83391189575195\n",
      "loss: 42.29005813598633\n",
      "loss: 17.348464965820312\n",
      "loss: 31.55790901184082\n",
      "loss: 49.6414680480957\n",
      "loss: 41.642940521240234\n",
      "loss: 23.73175811767578\n",
      "loss: 35.37620544433594\n",
      "loss: 45.16880798339844\n",
      "loss: 35.67906951904297\n",
      "loss: 23.216323852539062\n",
      "loss: 35.91463851928711\n",
      "loss: 47.45108413696289\n",
      "loss: 41.548675537109375\n",
      "loss: 30.642255783081055\n",
      "loss: 43.088321685791016\n",
      "loss: 49.50861740112305\n",
      "loss: 40.70413589477539\n",
      "loss: 19.151161193847656\n",
      "loss: 37.596561431884766\n",
      "loss: 44.434791564941406\n",
      "loss: 41.716007232666016\n",
      "loss: 22.6918888092041\n",
      "loss: 38.478981018066406\n",
      "loss: 46.986270904541016\n",
      "loss: 40.755401611328125\n",
      "loss: 18.2041072845459\n",
      "loss: 35.817230224609375\n",
      "loss: 50.65580749511719\n",
      "loss: 36.279151916503906\n",
      "loss: 22.204269409179688\n",
      "loss: 36.198524475097656\n",
      "loss: 52.889015197753906\n",
      "loss: 38.675167083740234\n",
      "loss: 21.626739501953125\n",
      "loss: 38.5638427734375\n",
      "loss: 45.10674285888672\n",
      "loss: 47.47713851928711\n",
      "loss: 24.848724365234375\n",
      "loss: 33.82734298706055\n",
      "loss: 49.55372619628906\n",
      "loss: 42.60037612915039\n",
      "loss: 16.62694549560547\n",
      "loss: 32.66442108154297\n",
      "loss: 51.95222854614258\n",
      "loss: 38.76664733886719\n",
      "loss: 26.289825439453125\n",
      "loss: 40.680667877197266\n",
      "loss: 47.665802001953125\n",
      "loss: 39.57341766357422\n",
      "loss: 25.422290802001953\n",
      "loss: 35.77705764770508\n",
      "loss: 44.61429977416992\n",
      "loss: 47.97111511230469\n",
      "loss: 17.439634323120117\n",
      "loss: 33.35530471801758\n",
      "loss: 50.1403923034668\n",
      "loss: 49.14591979980469\n",
      "loss: 28.254440307617188\n",
      "loss: 35.55357360839844\n",
      "loss: 52.47671890258789\n",
      "loss: 40.83018112182617\n",
      "loss: 17.853527069091797\n",
      "loss: 33.661231994628906\n",
      "loss: 47.588130950927734\n",
      "loss: 45.18315124511719\n",
      "loss: 22.404325485229492\n",
      "loss: 35.135929107666016\n",
      "loss: 54.951210021972656\n",
      "loss: 39.635032653808594\n",
      "loss: 21.143009185791016\n",
      "loss: 30.534637451171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 41.75934982299805\n",
      "loss: 43.973384857177734\n",
      "loss: 24.65531349182129\n",
      "loss: 35.26808166503906\n",
      "loss: 50.02027130126953\n",
      "loss: 43.56224822998047\n",
      "loss: 31.22261619567871\n",
      "loss: 34.82826232910156\n",
      "loss: 47.66535568237305\n",
      "loss: 35.68125534057617\n",
      "loss: 21.564210891723633\n",
      "loss: 33.73727035522461\n",
      "loss: 39.25083923339844\n",
      "loss: 33.14562225341797\n",
      "loss: 20.801406860351562\n",
      "loss: 33.1852912902832\n",
      "loss: 43.35874938964844\n",
      "loss: 42.76700973510742\n",
      "loss: 22.89787483215332\n",
      "loss: 30.387516021728516\n",
      "loss: 56.898658752441406\n",
      "loss: 39.246910095214844\n",
      "loss: 18.21648597717285\n",
      "loss: 30.53596305847168\n",
      "loss: 42.892127990722656\n",
      "loss: 40.55101013183594\n",
      "loss: 18.3188419342041\n",
      "loss: 33.61196517944336\n",
      "loss: 53.78633499145508\n",
      "loss: 38.814693450927734\n",
      "loss: 23.877548217773438\n",
      "loss: 32.77232360839844\n",
      "loss: 51.19873046875\n",
      "loss: 34.91233825683594\n",
      "loss: 20.26171112060547\n",
      "loss: 32.92099380493164\n",
      "loss: 41.304752349853516\n",
      "loss: 40.18426513671875\n",
      "loss: 18.778078079223633\n",
      "loss: 32.636474609375\n",
      "loss: 54.72296142578125\n",
      "loss: 37.964988708496094\n",
      "loss: 23.783123016357422\n",
      "loss: 36.17466354370117\n",
      "loss: 50.06520080566406\n",
      "loss: 45.32558822631836\n",
      "loss: 15.656447410583496\n",
      "loss: 33.57136154174805\n",
      "loss: 46.16749954223633\n",
      "loss: 43.52073287963867\n",
      "loss: 27.8715763092041\n",
      "loss: 34.50163269042969\n",
      "loss: 46.107791900634766\n",
      "loss: 36.1876335144043\n",
      "loss: 19.36750602722168\n",
      "loss: 28.628089904785156\n",
      "loss: 48.85508346557617\n",
      "loss: 42.273590087890625\n",
      "loss: 18.69343376159668\n",
      "loss: 33.58306884765625\n",
      "loss: 41.55880355834961\n",
      "loss: 35.55400466918945\n",
      "loss: 26.453594207763672\n",
      "loss: 36.26028823852539\n",
      "loss: 43.69675064086914\n",
      "loss: 30.81951141357422\n",
      "loss: 19.63063621520996\n",
      "loss: 35.630088806152344\n",
      "loss: 47.9654541015625\n",
      "loss: 36.054203033447266\n",
      "loss: 23.49112319946289\n",
      "loss: 39.13766098022461\n",
      "loss: 39.55678176879883\n",
      "loss: 39.48350524902344\n",
      "loss: 22.92304229736328\n",
      "loss: 33.36659622192383\n",
      "loss: 51.796566009521484\n",
      "loss: 33.448394775390625\n",
      "loss: 22.54418182373047\n",
      "loss: 32.880733489990234\n",
      "loss: 45.423095703125\n",
      "loss: 35.0373649597168\n",
      "loss: 17.304237365722656\n",
      "loss: 38.216339111328125\n",
      "loss: 44.038570404052734\n",
      "loss: 37.09929275512695\n",
      "loss: 27.913047790527344\n",
      "loss: 35.32577896118164\n",
      "loss: 47.20029830932617\n",
      "loss: 40.87208938598633\n",
      "loss: 17.50627326965332\n",
      "loss: 35.661415100097656\n",
      "loss: 43.18418502807617\n",
      "loss: 42.910804748535156\n",
      "loss: 19.153194427490234\n",
      "loss: 32.97346878051758\n",
      "loss: 43.433753967285156\n",
      "loss: 40.40890884399414\n",
      "loss: 16.019622802734375\n",
      "loss: 29.38608169555664\n",
      "loss: 41.845821380615234\n",
      "loss: 39.09635543823242\n",
      "loss: 21.530729293823242\n",
      "loss: 30.713577270507812\n",
      "loss: 36.08921813964844\n",
      "loss: 36.24876403808594\n",
      "loss: 17.478336334228516\n",
      "loss: 35.939579010009766\n",
      "loss: 45.341407775878906\n",
      "loss: 41.7106819152832\n",
      "loss: 23.220905303955078\n",
      "loss: 31.561885833740234\n",
      "loss: 41.12401580810547\n",
      "loss: 36.7130012512207\n",
      "loss: 17.192007064819336\n",
      "loss: 32.63005447387695\n",
      "loss: 44.8593864440918\n",
      "loss: 38.79073715209961\n",
      "loss: 16.128936767578125\n",
      "loss: 30.23651695251465\n",
      "loss: 40.391719818115234\n",
      "loss: 35.5709114074707\n",
      "loss: 25.672847747802734\n",
      "loss: 32.68899154663086\n",
      "loss: 41.75171661376953\n",
      "loss: 43.528648376464844\n",
      "loss: 17.939781188964844\n",
      "loss: 33.563926696777344\n",
      "loss: 41.88441848754883\n",
      "loss: 33.822696685791016\n",
      "loss: 16.330549240112305\n",
      "loss: 31.01481056213379\n",
      "loss: 41.68125534057617\n",
      "loss: 35.28339767456055\n",
      "loss: 19.711748123168945\n",
      "loss: 28.97063636779785\n",
      "loss: 34.67810821533203\n",
      "loss: 36.48765182495117\n",
      "loss: 17.8690185546875\n",
      "loss: 34.803436279296875\n",
      "loss: 53.72043228149414\n",
      "loss: 39.818443298339844\n",
      "loss: 18.397260665893555\n",
      "loss: 36.24062728881836\n",
      "loss: 46.19274139404297\n",
      "loss: 39.603153228759766\n",
      "loss: 22.71186637878418\n",
      "loss: 36.48044204711914\n",
      "loss: 48.39967346191406\n",
      "loss: 46.47293472290039\n",
      "loss: 21.1020450592041\n",
      "loss: 33.78180694580078\n",
      "loss: 48.744564056396484\n",
      "loss: 33.73533248901367\n",
      "loss: 24.04529571533203\n",
      "loss: 35.166629791259766\n",
      "loss: 49.18459701538086\n",
      "loss: 40.250797271728516\n",
      "loss: 16.490007400512695\n",
      "loss: 33.288333892822266\n",
      "loss: 48.55912399291992\n",
      "loss: 43.907958984375\n",
      "loss: 17.098039627075195\n",
      "loss: 36.967384338378906\n",
      "loss: 41.153526306152344\n",
      "loss: 32.104679107666016\n",
      "loss: 12.836092948913574\n",
      "loss: 35.37010192871094\n",
      "loss: 42.48927307128906\n",
      "loss: 28.416118621826172\n",
      "loss: 22.567068099975586\n",
      "loss: 34.121761322021484\n",
      "loss: 39.014259338378906\n",
      "loss: 35.380130767822266\n",
      "loss: 20.34967803955078\n",
      "loss: 30.686670303344727\n",
      "loss: 42.3891487121582\n",
      "loss: 34.53422164916992\n",
      "loss: 18.431434631347656\n",
      "loss: 26.640911102294922\n",
      "loss: 39.3436164855957\n",
      "loss: 34.68494415283203\n",
      "loss: 17.25884437561035\n",
      "loss: 30.22239112854004\n",
      "loss: 40.7934455871582\n",
      "loss: 32.96054458618164\n",
      "loss: 21.319833755493164\n",
      "loss: 31.207868576049805\n",
      "loss: 48.52212905883789\n",
      "loss: 32.01811218261719\n",
      "loss: 14.0870361328125\n",
      "loss: 26.811363220214844\n",
      "loss: 40.632484436035156\n",
      "loss: 39.90317916870117\n",
      "loss: 16.869741439819336\n",
      "loss: 29.702951431274414\n",
      "loss: 45.93815231323242\n",
      "loss: 37.768009185791016\n",
      "loss: 35.781982421875\n",
      "loss: 30.062744140625\n",
      "loss: 39.69349670410156\n",
      "loss: 38.994834899902344\n",
      "loss: 19.36750602722168\n",
      "loss: 32.013553619384766\n",
      "loss: 36.9044189453125\n",
      "loss: 32.17860794067383\n",
      "loss: 20.433467864990234\n",
      "loss: 34.46378707885742\n",
      "loss: 43.97161102294922\n",
      "loss: 36.02690887451172\n",
      "loss: 17.319910049438477\n",
      "loss: 29.016769409179688\n",
      "loss: 50.51495361328125\n",
      "loss: 38.945892333984375\n",
      "loss: 15.94285774230957\n",
      "loss: 32.20097732543945\n",
      "loss: 40.25409698486328\n",
      "loss: 39.163326263427734\n",
      "loss: 21.238130569458008\n",
      "loss: 29.334304809570312\n",
      "loss: 43.23551559448242\n",
      "loss: 35.13907241821289\n",
      "loss: 19.025680541992188\n",
      "loss: 28.22888946533203\n",
      "loss: 40.40266799926758\n",
      "loss: 37.40838623046875\n",
      "loss: 17.34780502319336\n",
      "loss: 37.06270980834961\n",
      "loss: 45.26504135131836\n",
      "loss: 33.920494079589844\n",
      "loss: 19.09599494934082\n",
      "loss: 35.124122619628906\n",
      "loss: 40.899776458740234\n",
      "loss: 39.81759262084961\n",
      "loss: 15.415641784667969\n",
      "loss: 28.70427131652832\n",
      "loss: 40.39950942993164\n",
      "loss: 33.83913803100586\n",
      "loss: 18.51590347290039\n",
      "loss: 33.51329803466797\n",
      "loss: 42.20158386230469\n",
      "loss: 32.0913200378418\n",
      "loss: 18.866863250732422\n",
      "loss: 31.038616180419922\n",
      "loss: 36.808773040771484\n",
      "loss: 31.67380142211914\n",
      "loss: 16.488754272460938\n",
      "loss: 33.99373245239258\n",
      "loss: 38.800201416015625\n",
      "loss: 35.314327239990234\n",
      "loss: 20.851184844970703\n",
      "loss: 33.0876350402832\n",
      "loss: 40.66739273071289\n",
      "loss: 34.49098587036133\n",
      "loss: 21.06317901611328\n",
      "loss: 29.038158416748047\n",
      "loss: 39.0775032043457\n",
      "loss: 34.06327438354492\n",
      "loss: 15.838635444641113\n",
      "loss: 29.250417709350586\n",
      "loss: 43.93868637084961\n",
      "loss: 33.627708435058594\n",
      "loss: 22.566932678222656\n",
      "loss: 35.3777961730957\n",
      "loss: 39.12834548950195\n",
      "loss: 30.456619262695312\n",
      "loss: 20.22637939453125\n",
      "loss: 29.430662155151367\n",
      "loss: 48.95484924316406\n",
      "loss: 34.82843780517578\n",
      "loss: 16.844619750976562\n",
      "loss: 33.00461196899414\n",
      "loss: 48.69340515136719\n",
      "loss: 31.802583694458008\n",
      "loss: 23.78591537475586\n",
      "loss: 32.96261215209961\n",
      "loss: 39.44011688232422\n",
      "loss: 27.77984046936035\n",
      "loss: 16.75420379638672\n",
      "loss: 31.134050369262695\n",
      "loss: 41.362911224365234\n",
      "loss: 33.486328125\n",
      "loss: 17.296649932861328\n",
      "loss: 28.61765480041504\n",
      "loss: 34.83161926269531\n",
      "loss: 34.627281188964844\n",
      "loss: 16.914533615112305\n",
      "loss: 30.2971134185791\n",
      "loss: 42.36579132080078\n",
      "loss: 33.37645721435547\n",
      "loss: 19.873655319213867\n",
      "loss: 32.25952911376953\n",
      "loss: 41.810035705566406\n",
      "loss: 32.477088928222656\n",
      "loss: 20.011856079101562\n",
      "loss: 22.820730209350586\n",
      "loss: 42.164100646972656\n",
      "loss: 36.225189208984375\n",
      "loss: 16.882186889648438\n",
      "loss: 27.476726531982422\n",
      "loss: 43.09518814086914\n",
      "loss: 34.89042663574219\n",
      "loss: 21.617807388305664\n",
      "loss: 26.434341430664062\n",
      "loss: 48.894649505615234\n",
      "loss: 32.94203186035156\n",
      "loss: 22.09596824645996\n",
      "loss: 33.52532958984375\n",
      "loss: 40.442359924316406\n",
      "loss: 36.75646209716797\n",
      "loss: 12.553034782409668\n",
      "loss: 32.692256927490234\n",
      "loss: 43.745811462402344\n",
      "loss: 34.094539642333984\n",
      "loss: 18.322677612304688\n",
      "loss: 32.33291244506836\n",
      "loss: 38.85093307495117\n",
      "loss: 42.148902893066406\n",
      "loss: 17.93902015686035\n",
      "loss: 32.60342788696289\n",
      "loss: 41.727508544921875\n",
      "loss: 34.073978424072266\n",
      "loss: 24.318416595458984\n",
      "loss: 29.26630401611328\n",
      "loss: 33.157264709472656\n",
      "loss: 45.428131103515625\n",
      "loss: 14.897068977355957\n",
      "loss: 30.665485382080078\n",
      "loss: 38.04994201660156\n",
      "loss: 27.269676208496094\n",
      "loss: 24.505359649658203\n",
      "loss: 28.221773147583008\n",
      "loss: 39.01327133178711\n",
      "loss: 34.916629791259766\n",
      "loss: 15.391966819763184\n",
      "loss: 29.38813018798828\n",
      "loss: 42.02490997314453\n",
      "loss: 28.213394165039062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 18.265182495117188\n",
      "loss: 37.327659606933594\n",
      "loss: 42.7440299987793\n",
      "loss: 35.03252029418945\n",
      "loss: 15.861538887023926\n",
      "loss: 29.39775276184082\n",
      "loss: 39.8787841796875\n",
      "loss: 34.89787673950195\n",
      "loss: 21.64488410949707\n",
      "loss: 27.571138381958008\n",
      "loss: 44.19996643066406\n",
      "loss: 32.20074462890625\n",
      "loss: 17.017173767089844\n",
      "loss: 27.908605575561523\n",
      "loss: 39.701602935791016\n",
      "loss: 39.860408782958984\n",
      "loss: 17.251171112060547\n",
      "loss: 28.165021896362305\n",
      "loss: 38.12971115112305\n",
      "loss: 29.663135528564453\n",
      "loss: 19.512147903442383\n",
      "loss: 33.08592987060547\n",
      "loss: 38.21183395385742\n",
      "loss: 33.36843490600586\n",
      "loss: 26.843341827392578\n",
      "loss: 30.860517501831055\n",
      "loss: 35.80459213256836\n",
      "loss: 39.02946853637695\n",
      "loss: 13.852197647094727\n",
      "loss: 27.070894241333008\n",
      "loss: 37.496910095214844\n",
      "loss: 34.72197341918945\n",
      "loss: 16.126737594604492\n",
      "loss: 29.805252075195312\n",
      "loss: 38.215641021728516\n",
      "loss: 32.134220123291016\n",
      "loss: 21.427255630493164\n",
      "loss: 27.60041046142578\n",
      "loss: 37.61056900024414\n",
      "loss: 31.958492279052734\n",
      "loss: 21.26130485534668\n",
      "loss: 31.699386596679688\n",
      "loss: 40.46793746948242\n",
      "loss: 41.25932312011719\n",
      "loss: 16.209341049194336\n",
      "loss: 29.847566604614258\n",
      "loss: 39.5447883605957\n",
      "loss: 32.46693420410156\n",
      "loss: 29.45912742614746\n",
      "loss: 29.464078903198242\n",
      "loss: 40.12062072753906\n",
      "loss: 37.34709930419922\n",
      "loss: 17.884464263916016\n",
      "loss: 30.842090606689453\n",
      "loss: 44.60771560668945\n",
      "loss: 36.47003173828125\n",
      "loss: 20.890430450439453\n",
      "loss: 35.157379150390625\n",
      "loss: 43.41864776611328\n",
      "loss: 39.02754592895508\n",
      "loss: 20.344032287597656\n",
      "loss: 28.456798553466797\n",
      "loss: 41.610233306884766\n",
      "loss: 34.76785659790039\n",
      "loss: 22.500350952148438\n",
      "loss: 31.16718292236328\n",
      "loss: 38.76047897338867\n",
      "loss: 25.290559768676758\n",
      "loss: 16.824411392211914\n",
      "loss: 29.405258178710938\n",
      "loss: 40.11293411254883\n",
      "loss: 31.05550765991211\n",
      "loss: 18.263057708740234\n",
      "loss: 28.380435943603516\n",
      "loss: 33.187870025634766\n",
      "loss: 33.36248016357422\n",
      "loss: 16.99225616455078\n",
      "loss: 29.42312240600586\n",
      "loss: 36.19963836669922\n",
      "loss: 32.302879333496094\n",
      "loss: 15.784287452697754\n",
      "loss: 29.04996681213379\n",
      "loss: 40.55437469482422\n",
      "loss: 27.391571044921875\n",
      "loss: 19.718318939208984\n",
      "loss: 24.193449020385742\n",
      "loss: 39.87018585205078\n",
      "loss: 32.13105010986328\n",
      "loss: 14.635435104370117\n",
      "loss: 27.327245712280273\n",
      "loss: 30.86089324951172\n",
      "loss: 28.215911865234375\n",
      "loss: 24.35594367980957\n",
      "loss: 28.002147674560547\n",
      "loss: 41.13529586791992\n",
      "loss: 35.46018600463867\n",
      "loss: 19.09920883178711\n",
      "loss: 29.34333038330078\n",
      "loss: 36.2252082824707\n",
      "loss: 30.19199562072754\n",
      "loss: 11.135009765625\n",
      "loss: 32.9193229675293\n",
      "loss: 38.28129577636719\n",
      "loss: 31.388195037841797\n",
      "loss: 18.89370346069336\n",
      "loss: 30.279399871826172\n",
      "loss: 42.86404800415039\n",
      "loss: 28.138181686401367\n",
      "loss: 19.557416915893555\n",
      "loss: 27.89930534362793\n",
      "loss: 35.764060974121094\n",
      "loss: 32.71775436401367\n",
      "loss: 18.189695358276367\n",
      "loss: 31.795499801635742\n",
      "loss: 33.8914909362793\n",
      "loss: 28.436830520629883\n",
      "loss: 20.634117126464844\n",
      "loss: 32.47031784057617\n",
      "loss: 42.56305694580078\n",
      "loss: 33.77777862548828\n",
      "loss: 13.02478313446045\n",
      "loss: 29.415084838867188\n",
      "loss: 40.34696960449219\n",
      "loss: 28.907224655151367\n",
      "loss: 20.87774658203125\n",
      "loss: 25.552152633666992\n",
      "loss: 52.050758361816406\n",
      "loss: 28.318674087524414\n",
      "loss: 19.555330276489258\n",
      "loss: 30.63815689086914\n",
      "loss: 44.357181549072266\n",
      "loss: 29.72283935546875\n",
      "loss: 21.64905548095703\n",
      "loss: 26.236553192138672\n",
      "loss: 36.368717193603516\n",
      "loss: 33.682674407958984\n",
      "loss: 18.372732162475586\n",
      "loss: 26.520187377929688\n",
      "loss: 46.954097747802734\n",
      "loss: 33.31787109375\n",
      "loss: 20.824934005737305\n",
      "loss: 32.979427337646484\n",
      "loss: 30.682273864746094\n",
      "loss: 33.58842849731445\n",
      "loss: 18.965984344482422\n",
      "loss: 33.77219009399414\n",
      "loss: 37.210052490234375\n",
      "loss: 31.86743927001953\n",
      "loss: 20.98497200012207\n",
      "loss: 30.733407974243164\n",
      "loss: 41.59062194824219\n",
      "loss: 31.314573287963867\n",
      "loss: 20.103748321533203\n",
      "loss: 27.262784957885742\n",
      "loss: 40.870052337646484\n",
      "loss: 33.50446701049805\n",
      "loss: 17.49634552001953\n",
      "loss: 31.587671279907227\n",
      "loss: 46.91023635864258\n",
      "loss: 30.4339542388916\n",
      "loss: 18.8973331451416\n",
      "loss: 31.445581436157227\n",
      "loss: 36.182533264160156\n",
      "loss: 34.330875396728516\n",
      "loss: 16.73285484313965\n",
      "loss: 26.05436134338379\n",
      "loss: 36.44493865966797\n",
      "loss: 29.143016815185547\n",
      "loss: 20.570579528808594\n",
      "loss: 27.59502601623535\n",
      "loss: 49.0457763671875\n",
      "loss: 27.62034034729004\n",
      "loss: 18.158945083618164\n",
      "loss: 32.849647521972656\n",
      "loss: 37.12588882446289\n",
      "loss: 37.08399200439453\n",
      "loss: 21.509445190429688\n",
      "loss: 29.984758377075195\n",
      "loss: 41.089012145996094\n",
      "loss: 30.366897583007812\n",
      "loss: 21.713314056396484\n",
      "loss: 29.82598304748535\n",
      "loss: 44.89997482299805\n",
      "loss: 35.64146423339844\n",
      "loss: 15.955560684204102\n",
      "loss: 34.043975830078125\n",
      "loss: 38.25792694091797\n",
      "loss: 27.562702178955078\n",
      "loss: 24.056968688964844\n",
      "loss: 25.699542999267578\n",
      "loss: 32.26131820678711\n",
      "loss: 39.75563049316406\n",
      "loss: 19.720256805419922\n",
      "loss: 34.632389068603516\n",
      "loss: 40.74601745605469\n",
      "loss: 30.502138137817383\n",
      "loss: 17.56852149963379\n",
      "loss: 29.008708953857422\n",
      "loss: 36.87506866455078\n",
      "loss: 31.63544273376465\n",
      "loss: 24.327821731567383\n",
      "loss: 27.170202255249023\n",
      "loss: 37.79118728637695\n",
      "loss: 29.183998107910156\n",
      "loss: 15.576021194458008\n",
      "loss: 31.357196807861328\n",
      "loss: 41.67048645019531\n",
      "loss: 30.91950035095215\n",
      "loss: 15.350933074951172\n",
      "loss: 28.086559295654297\n",
      "loss: 42.36185836791992\n",
      "loss: 33.001121520996094\n",
      "loss: 18.70587921142578\n",
      "loss: 30.471311569213867\n",
      "loss: 40.50898742675781\n",
      "loss: 30.515939712524414\n",
      "loss: 18.82486343383789\n",
      "loss: 26.05925941467285\n",
      "loss: 41.36385726928711\n",
      "loss: 30.98008155822754\n",
      "loss: 18.294898986816406\n",
      "loss: 30.300373077392578\n",
      "loss: 33.26327133178711\n",
      "loss: 28.797420501708984\n",
      "loss: 17.747936248779297\n",
      "loss: 27.639141082763672\n",
      "loss: 39.96166229248047\n",
      "loss: 28.082508087158203\n",
      "loss: 15.3328275680542\n",
      "loss: 26.984621047973633\n",
      "loss: 36.522274017333984\n",
      "loss: 32.143463134765625\n",
      "loss: 24.94757080078125\n",
      "loss: 30.88204002380371\n",
      "loss: 33.728546142578125\n",
      "loss: 36.85178756713867\n",
      "loss: 18.410667419433594\n",
      "loss: 28.220735549926758\n",
      "loss: 37.3140983581543\n",
      "loss: 28.429229736328125\n",
      "loss: 22.188228607177734\n",
      "loss: 27.72969627380371\n",
      "loss: 41.21665573120117\n",
      "loss: 30.58637237548828\n",
      "loss: 12.868335723876953\n",
      "loss: 30.694257736206055\n",
      "loss: 38.64574432373047\n",
      "loss: 27.72588539123535\n",
      "loss: 22.399198532104492\n",
      "loss: 27.728897094726562\n",
      "loss: 34.60664749145508\n",
      "loss: 25.49336051940918\n",
      "loss: 18.915332794189453\n",
      "loss: 27.066099166870117\n",
      "loss: 39.03290939331055\n",
      "loss: 33.39670181274414\n",
      "loss: 23.479578018188477\n",
      "loss: 32.62530517578125\n",
      "loss: 38.72974395751953\n",
      "loss: 34.55094909667969\n",
      "loss: 18.827680587768555\n",
      "loss: 30.329572677612305\n",
      "loss: 32.77278518676758\n",
      "loss: 29.274991989135742\n",
      "loss: 23.489259719848633\n",
      "loss: 25.911603927612305\n",
      "loss: 34.50708770751953\n",
      "loss: 31.110244750976562\n",
      "loss: 17.629913330078125\n",
      "loss: 36.384273529052734\n",
      "loss: 35.549781799316406\n",
      "loss: 32.343685150146484\n",
      "loss: 19.326202392578125\n",
      "loss: 27.85701560974121\n",
      "loss: 47.485069274902344\n",
      "loss: 24.683820724487305\n",
      "loss: 21.38820457458496\n",
      "loss: 27.77691078186035\n",
      "loss: 40.89938735961914\n",
      "loss: 30.406557083129883\n",
      "loss: 17.765939712524414\n",
      "loss: 30.408557891845703\n"
     ]
    }
   ],
   "source": [
    "iterations = 1000000\n",
    "batch_size = 100\n",
    "goals = [[-0.09, 0.86], [-0.09, 0.89], [0.07, 0.86], [0.07, 0.89]]\n",
    "for it in range(iterations):\n",
    "    for goal_idx in range(4):\n",
    "#         goal_idx = 3\n",
    "        goal = torch.Tensor(goals[goal_idx])\n",
    "        s, a, next_s, r, d = replay_buffers[goal_idx].sample(batch_size)\n",
    "#         print(s)\n",
    "        loss = 0\n",
    "        for state in s:\n",
    "            ss = torch.Tensor(state)\n",
    "#             print(ss, ss.shape)\n",
    "            target_action = target_actors[goal_idx](ss)\n",
    "    #         print(target_action)\n",
    "            pred_action = torch.mul(goal_MLP(goal), state_MLP(ss))\n",
    "    \n",
    "            loss += F.mse_loss(pred_action, target_action)\n",
    "        print(\"loss:\",loss.item())\n",
    "        wandb.log({\"loss\": loss.item(), \"step\": it})\n",
    "        \n",
    "        goal_MLP.zero_grad()\n",
    "        state_MLP.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        goal_optimizer.step()\n",
    "        state_optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLenv",
   "language": "python",
   "name": "rlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}